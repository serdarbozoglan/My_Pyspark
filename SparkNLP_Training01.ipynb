{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SparkNLP_Training01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNG1l6i7eXC1wrc4CZzZB8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/serdarbozoglan/My_Pyspark/blob/master/SparkNLP_Training01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_E0GxcFrATu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "5b35f8f7-7cf0-4d96-d531-a4166726aa17"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.4.5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_242\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.242-b08, mixed mode)\n",
            "Collecting pyspark==2.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 69kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 52.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=2bef30878b01f7c702686d85111ee7d4084340af0e3da14e08562b0235a15026\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n",
            "Collecting spark-nlp==2.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/46/5c5a2bda407f693126386da5378f132e5e163fa6dfa46109548270348786/spark_nlp-2.4.5-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 5.1MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYfRI1sCIlOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lmOKqb3wYmi",
        "colab_type": "text"
      },
      "source": [
        "## Start Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBXyJUAyrSXP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0b5fdd2e-6119-4878-8146-84eea0ad7d8a"
      },
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print('Spark NLP Version : ', sparknlp.version())\n",
        "print('Apache Spark Version :', spark.version)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP Version :  2.4.5\n",
            "Apache Spark Version : 2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_8WNsDjxibK",
        "colab_type": "text"
      },
      "source": [
        "## Using Pretrained Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKx2DGFPxtbJ",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/JohnSnowLabs/spark-nlp-models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alFZ1XjCxtSa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjNHvZUpwxNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6ef0c56b-24bc-4f45-99fa-0d0f3c320bf1"
      },
      "source": [
        "pipeline = PretrainedPipeline('explain_document_ml', lang='en')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explain_document_ml download started this may take some time.\n",
            "Approx size to download 9.4 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIKWJt0Fy8gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testDoc = \"\"\"French author who helped pioner the science-fiction genre. \\\n",
        "Verne wrate about space, air, and underwater travel before navigable aircrast and \\\n",
        "practical submarines were invented, and before any means of space travel had been devised.\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXvUosLUz3i5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9d1bf0ea-e340-4a20-df8e-ba52a9ed05cd"
      },
      "source": [
        "testDoc"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'French author who helped pioner the science-fiction genre. Verne wrate about space, air, and underwater travel before navigable aircrast and practical submarines were invented, and before any means of space travel had been devised.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m5nUlVSz7iU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9d2428c9-c11b-4ba3-e429-1e1d21c1cfad"
      },
      "source": [
        "%%time\n",
        "\n",
        "result = pipeline.annotate(testDoc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 34.9 ms, sys: 9.77 ms, total: 44.6 ms\n",
            "Wall time: 2.26 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6gqwXHZ0HuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87c31ceb-b74f-4c12-aa4c-dc03116c3243"
      },
      "source": [
        "result.keys()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'spell', 'pos', 'lemmas', 'token', 'stems', 'sentence'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBtaJpxm0n84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2a403ac4-58a2-4ee5-c046-edaad9f84a11"
      },
      "source": [
        "result['sentence']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['French author who helped pioner the science-fiction genre.',\n",
              " 'Verne wrate about space, air, and underwater travel before navigable aircrast and practical submarines were invented, and before any means of space travel had been devised.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxGKhrNe0yIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "6fbaae98-daaa-4036-9f22-6bdc853791f6"
      },
      "source": [
        "result['token']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['French',\n",
              " 'author',\n",
              " 'who',\n",
              " 'helped',\n",
              " 'pioner',\n",
              " 'the',\n",
              " 'science-fiction',\n",
              " 'genre',\n",
              " '.',\n",
              " 'Verne',\n",
              " 'wrate',\n",
              " 'about',\n",
              " 'space',\n",
              " ',',\n",
              " 'air',\n",
              " ',',\n",
              " 'and',\n",
              " 'underwater',\n",
              " 'travel',\n",
              " 'before',\n",
              " 'navigable',\n",
              " 'aircrast',\n",
              " 'and',\n",
              " 'practical',\n",
              " 'submarines',\n",
              " 'were',\n",
              " 'invented',\n",
              " ',',\n",
              " 'and',\n",
              " 'before',\n",
              " 'any',\n",
              " 'means',\n",
              " 'of',\n",
              " 'space',\n",
              " 'travel',\n",
              " 'had',\n",
              " 'been',\n",
              " 'devised',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPBB1A1J0z1g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "f69e9ae3-93e3-4a7d-907d-ad2a2d610b3a"
      },
      "source": [
        "list(zip(result['token'], result['pos']))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('French', 'JJ'),\n",
              " ('author', 'NN'),\n",
              " ('who', 'WP'),\n",
              " ('helped', 'VBD'),\n",
              " ('pioner', 'NN'),\n",
              " ('the', 'DT'),\n",
              " ('science-fiction', 'NN'),\n",
              " ('genre', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Verne', 'NNP'),\n",
              " ('wrate', 'VBD'),\n",
              " ('about', 'IN'),\n",
              " ('space', 'NN'),\n",
              " (',', ','),\n",
              " ('air', 'NN'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('underwater', 'JJ'),\n",
              " ('travel', 'NN'),\n",
              " ('before', 'IN'),\n",
              " ('navigable', 'JJ'),\n",
              " ('aircrast', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('practical', 'JJ'),\n",
              " ('submarines', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('invented', 'VBN'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('before', 'IN'),\n",
              " ('any', 'DT'),\n",
              " ('means', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('space', 'NN'),\n",
              " ('travel', 'NN'),\n",
              " ('had', 'VBD'),\n",
              " ('been', 'VBN'),\n",
              " ('devised', 'VBN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fL_GxQ71Rat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "9c3a6097-fec6-4fc2-ae3f-4724d8692401"
      },
      "source": [
        "list(zip(result['token'], result['lemmas'], result['stems'], result['spell']))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('French', 'French', 'french', 'French'),\n",
              " ('author', 'author', 'author', 'author'),\n",
              " ('who', 'who', 'who', 'who'),\n",
              " ('helped', 'help', 'help', 'helped'),\n",
              " ('pioner', 'pioneer', 'pioneer', 'pioneer'),\n",
              " ('the', 'the', 'the', 'the'),\n",
              " ('science-fiction', 'sciencefiction', 'sciencefict', 'sciencefiction'),\n",
              " ('genre', 'genre', 'genr', 'genre'),\n",
              " ('.', '.', '.', '.'),\n",
              " ('Verne', 'Verne', 'vern', 'Verne'),\n",
              " ('wrate', 'write', 'wrote', 'wrote'),\n",
              " ('about', 'about', 'about', 'about'),\n",
              " ('space', 'space', 'space', 'space'),\n",
              " (',', ',', ',', ','),\n",
              " ('air', 'air', 'air', 'air'),\n",
              " (',', ',', ',', ','),\n",
              " ('and', 'and', 'and', 'and'),\n",
              " ('underwater', 'underwater', 'underwat', 'underwater'),\n",
              " ('travel', 'travel', 'travel', 'travel'),\n",
              " ('before', 'before', 'befor', 'before'),\n",
              " ('navigable', 'navigable', 'navig', 'navigable'),\n",
              " ('aircrast', 'aircraft', 'aircraft', 'aircraft'),\n",
              " ('and', 'and', 'and', 'and'),\n",
              " ('practical', 'practical', 'practic', 'practical'),\n",
              " ('submarines', 'submarine', 'submarin', 'submarines'),\n",
              " ('were', 'be', 'were', 'were'),\n",
              " ('invented', 'invent', 'invent', 'invented'),\n",
              " (',', ',', ',', ','),\n",
              " ('and', 'and', 'and', 'and'),\n",
              " ('before', 'before', 'befor', 'before'),\n",
              " ('any', 'any', 'ani', 'any'),\n",
              " ('means', 'mean', 'mean', 'means'),\n",
              " ('of', 'of', 'of', 'of'),\n",
              " ('space', 'space', 'space', 'space'),\n",
              " ('travel', 'travel', 'travel', 'travel'),\n",
              " ('had', 'have', 'had', 'had'),\n",
              " ('been', 'be', 'been', 'been'),\n",
              " ('devised', 'devise', 'devis', 'devised'),\n",
              " ('.', '.', '.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LUM2iOp1jiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "929af8dc-b595-4803-bfcc-95d843fc39bf"
      },
      "source": [
        "df = pd.DataFrame({\"token\":result['token'],\n",
        "                   \"corrected\":result['spell'],\n",
        "                   'POS':result['pos'],\n",
        "                   'lemmas':result['lemmas'],\n",
        "                   'stems':result['stems']}) \n",
        "df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>corrected</th>\n",
              "      <th>POS</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>stems</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>French</td>\n",
              "      <td>French</td>\n",
              "      <td>JJ</td>\n",
              "      <td>French</td>\n",
              "      <td>french</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>author</td>\n",
              "      <td>author</td>\n",
              "      <td>NN</td>\n",
              "      <td>author</td>\n",
              "      <td>author</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>who</td>\n",
              "      <td>who</td>\n",
              "      <td>WP</td>\n",
              "      <td>who</td>\n",
              "      <td>who</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>helped</td>\n",
              "      <td>helped</td>\n",
              "      <td>VBD</td>\n",
              "      <td>help</td>\n",
              "      <td>help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pioner</td>\n",
              "      <td>pioneer</td>\n",
              "      <td>NN</td>\n",
              "      <td>pioneer</td>\n",
              "      <td>pioneer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>science-fiction</td>\n",
              "      <td>sciencefiction</td>\n",
              "      <td>NN</td>\n",
              "      <td>sciencefiction</td>\n",
              "      <td>sciencefict</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>genre</td>\n",
              "      <td>genre</td>\n",
              "      <td>NN</td>\n",
              "      <td>genre</td>\n",
              "      <td>genr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Verne</td>\n",
              "      <td>Verne</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Verne</td>\n",
              "      <td>vern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>wrate</td>\n",
              "      <td>wrote</td>\n",
              "      <td>VBD</td>\n",
              "      <td>write</td>\n",
              "      <td>wrote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>about</td>\n",
              "      <td>about</td>\n",
              "      <td>IN</td>\n",
              "      <td>about</td>\n",
              "      <td>about</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>space</td>\n",
              "      <td>space</td>\n",
              "      <td>NN</td>\n",
              "      <td>space</td>\n",
              "      <td>space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>air</td>\n",
              "      <td>air</td>\n",
              "      <td>NN</td>\n",
              "      <td>air</td>\n",
              "      <td>air</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>underwater</td>\n",
              "      <td>underwater</td>\n",
              "      <td>JJ</td>\n",
              "      <td>underwater</td>\n",
              "      <td>underwat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>travel</td>\n",
              "      <td>travel</td>\n",
              "      <td>NN</td>\n",
              "      <td>travel</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>before</td>\n",
              "      <td>before</td>\n",
              "      <td>IN</td>\n",
              "      <td>before</td>\n",
              "      <td>befor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>navigable</td>\n",
              "      <td>navigable</td>\n",
              "      <td>JJ</td>\n",
              "      <td>navigable</td>\n",
              "      <td>navig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>aircrast</td>\n",
              "      <td>aircraft</td>\n",
              "      <td>NN</td>\n",
              "      <td>aircraft</td>\n",
              "      <td>aircraft</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>practical</td>\n",
              "      <td>practical</td>\n",
              "      <td>JJ</td>\n",
              "      <td>practical</td>\n",
              "      <td>practic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>submarines</td>\n",
              "      <td>submarines</td>\n",
              "      <td>NNS</td>\n",
              "      <td>submarine</td>\n",
              "      <td>submarin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>were</td>\n",
              "      <td>were</td>\n",
              "      <td>VBD</td>\n",
              "      <td>be</td>\n",
              "      <td>were</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>invented</td>\n",
              "      <td>invented</td>\n",
              "      <td>VBN</td>\n",
              "      <td>invent</td>\n",
              "      <td>invent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>before</td>\n",
              "      <td>before</td>\n",
              "      <td>IN</td>\n",
              "      <td>before</td>\n",
              "      <td>befor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>any</td>\n",
              "      <td>any</td>\n",
              "      <td>DT</td>\n",
              "      <td>any</td>\n",
              "      <td>ani</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>means</td>\n",
              "      <td>means</td>\n",
              "      <td>NNS</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>space</td>\n",
              "      <td>space</td>\n",
              "      <td>NN</td>\n",
              "      <td>space</td>\n",
              "      <td>space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>travel</td>\n",
              "      <td>travel</td>\n",
              "      <td>NN</td>\n",
              "      <td>travel</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>had</td>\n",
              "      <td>had</td>\n",
              "      <td>VBD</td>\n",
              "      <td>have</td>\n",
              "      <td>had</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>been</td>\n",
              "      <td>been</td>\n",
              "      <td>VBN</td>\n",
              "      <td>be</td>\n",
              "      <td>been</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>devised</td>\n",
              "      <td>devised</td>\n",
              "      <td>VBN</td>\n",
              "      <td>devise</td>\n",
              "      <td>devis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              token       corrected  POS          lemmas        stems\n",
              "0            French          French   JJ          French       french\n",
              "1            author          author   NN          author       author\n",
              "2               who             who   WP             who          who\n",
              "3            helped          helped  VBD            help         help\n",
              "4            pioner         pioneer   NN         pioneer      pioneer\n",
              "5               the             the   DT             the          the\n",
              "6   science-fiction  sciencefiction   NN  sciencefiction  sciencefict\n",
              "7             genre           genre   NN           genre         genr\n",
              "8                 .               .    .               .            .\n",
              "9             Verne           Verne  NNP           Verne         vern\n",
              "10            wrate           wrote  VBD           write        wrote\n",
              "11            about           about   IN           about        about\n",
              "12            space           space   NN           space        space\n",
              "13                ,               ,    ,               ,            ,\n",
              "14              air             air   NN             air          air\n",
              "15                ,               ,    ,               ,            ,\n",
              "16              and             and   CC             and          and\n",
              "17       underwater      underwater   JJ      underwater     underwat\n",
              "18           travel          travel   NN          travel       travel\n",
              "19           before          before   IN          before        befor\n",
              "20        navigable       navigable   JJ       navigable        navig\n",
              "21         aircrast        aircraft   NN        aircraft     aircraft\n",
              "22              and             and   CC             and          and\n",
              "23        practical       practical   JJ       practical      practic\n",
              "24       submarines      submarines  NNS       submarine     submarin\n",
              "25             were            were  VBD              be         were\n",
              "26         invented        invented  VBN          invent       invent\n",
              "27                ,               ,    ,               ,            ,\n",
              "28              and             and   CC             and          and\n",
              "29           before          before   IN          before        befor\n",
              "30              any             any   DT             any          ani\n",
              "31            means           means  NNS            mean         mean\n",
              "32               of              of   IN              of           of\n",
              "33            space           space   NN           space        space\n",
              "34           travel          travel   NN          travel       travel\n",
              "35              had             had  VBD            have          had\n",
              "36             been            been  VBN              be         been\n",
              "37          devised         devised  VBN          devise        devis\n",
              "38                .               .    .               .            ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zBKH09W3D7u",
        "colab_type": "text"
      },
      "source": [
        "## Explain Document DL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMbgcFPr2ss7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3463e592-2319-44cf-8abd-428f97977343"
      },
      "source": [
        "pipeline_dl = PretrainedPipeline('explain_document_dl', 'en')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explain_document_dl download started this may take some time.\n",
            "Approx size to download 168.4 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HN9R4jS3PyU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c2969da0-c1a4-43e8-df5c-b03ffae45299"
      },
      "source": [
        "%%time\n",
        "result = pipeline_dl.annotate(testDoc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 33.1 ms, sys: 12.7 ms, total: 45.8 ms\n",
            "Wall time: 724 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqRgbLR1G_TR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cf0b559-d6d3-4ff5-fe76-48bb1bd36ad6"
      },
      "source": [
        "result.keys()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['entities', 'stem', 'checked', 'lemma', 'document', 'pos', 'token', 'ner', 'embeddings', 'sentence'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_qxIJRrIJLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "208e1136-a725-4382-9faa-a4cab1b7048e"
      },
      "source": [
        "result['entities']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['French', 'Verne']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv88V9rTIcq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "374ada7e-5781-4ceb-c0f9-8cf5f856aeb5"
      },
      "source": [
        "df = pd.DataFrame({\"token\":result['token'],\n",
        "                   \"ner_label\":result['ner'],\n",
        "                   \"spell_corrected\":result['checked'],\n",
        "                   'POS':result['pos'],\n",
        "                   'lemma':result['lemma'],\n",
        "                   'stem':result['stem']}) \n",
        "df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>ner_label</th>\n",
              "      <th>spell_corrected</th>\n",
              "      <th>POS</th>\n",
              "      <th>lemma</th>\n",
              "      <th>stem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>French</td>\n",
              "      <td>B-MISC</td>\n",
              "      <td>French</td>\n",
              "      <td>JJ</td>\n",
              "      <td>French</td>\n",
              "      <td>french</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>author</td>\n",
              "      <td>O</td>\n",
              "      <td>author</td>\n",
              "      <td>NN</td>\n",
              "      <td>author</td>\n",
              "      <td>author</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>who</td>\n",
              "      <td>O</td>\n",
              "      <td>who</td>\n",
              "      <td>WP</td>\n",
              "      <td>who</td>\n",
              "      <td>who</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>helped</td>\n",
              "      <td>O</td>\n",
              "      <td>helped</td>\n",
              "      <td>VBD</td>\n",
              "      <td>help</td>\n",
              "      <td>help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pioner</td>\n",
              "      <td>O</td>\n",
              "      <td>pioneer</td>\n",
              "      <td>NN</td>\n",
              "      <td>pioneer</td>\n",
              "      <td>pioneer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>science-fiction</td>\n",
              "      <td>O</td>\n",
              "      <td>sciencefiction</td>\n",
              "      <td>NN</td>\n",
              "      <td>sciencefiction</td>\n",
              "      <td>sciencefict</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>genre</td>\n",
              "      <td>O</td>\n",
              "      <td>genre</td>\n",
              "      <td>NN</td>\n",
              "      <td>genre</td>\n",
              "      <td>genr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Verne</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>Verne</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Verne</td>\n",
              "      <td>vern</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>wrate</td>\n",
              "      <td>O</td>\n",
              "      <td>wrote</td>\n",
              "      <td>VBD</td>\n",
              "      <td>write</td>\n",
              "      <td>wrote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>about</td>\n",
              "      <td>O</td>\n",
              "      <td>about</td>\n",
              "      <td>IN</td>\n",
              "      <td>about</td>\n",
              "      <td>about</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>space</td>\n",
              "      <td>O</td>\n",
              "      <td>space</td>\n",
              "      <td>NN</td>\n",
              "      <td>space</td>\n",
              "      <td>space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>air</td>\n",
              "      <td>O</td>\n",
              "      <td>air</td>\n",
              "      <td>NN</td>\n",
              "      <td>air</td>\n",
              "      <td>air</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>underwater</td>\n",
              "      <td>O</td>\n",
              "      <td>underwater</td>\n",
              "      <td>JJ</td>\n",
              "      <td>underwater</td>\n",
              "      <td>underwat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>travel</td>\n",
              "      <td>O</td>\n",
              "      <td>travel</td>\n",
              "      <td>NN</td>\n",
              "      <td>travel</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>before</td>\n",
              "      <td>O</td>\n",
              "      <td>before</td>\n",
              "      <td>IN</td>\n",
              "      <td>before</td>\n",
              "      <td>befor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>navigable</td>\n",
              "      <td>O</td>\n",
              "      <td>navigable</td>\n",
              "      <td>JJ</td>\n",
              "      <td>navigable</td>\n",
              "      <td>navig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>aircrast</td>\n",
              "      <td>O</td>\n",
              "      <td>aircraft</td>\n",
              "      <td>NN</td>\n",
              "      <td>aircraft</td>\n",
              "      <td>aircraft</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>practical</td>\n",
              "      <td>O</td>\n",
              "      <td>practical</td>\n",
              "      <td>JJ</td>\n",
              "      <td>practical</td>\n",
              "      <td>practic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>submarines</td>\n",
              "      <td>O</td>\n",
              "      <td>submarines</td>\n",
              "      <td>NNS</td>\n",
              "      <td>submarine</td>\n",
              "      <td>submarin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>were</td>\n",
              "      <td>O</td>\n",
              "      <td>were</td>\n",
              "      <td>VBD</td>\n",
              "      <td>be</td>\n",
              "      <td>were</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>invented</td>\n",
              "      <td>O</td>\n",
              "      <td>invented</td>\n",
              "      <td>VBN</td>\n",
              "      <td>invent</td>\n",
              "      <td>invent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>before</td>\n",
              "      <td>O</td>\n",
              "      <td>before</td>\n",
              "      <td>IN</td>\n",
              "      <td>before</td>\n",
              "      <td>befor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>any</td>\n",
              "      <td>O</td>\n",
              "      <td>any</td>\n",
              "      <td>DT</td>\n",
              "      <td>any</td>\n",
              "      <td>ani</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>means</td>\n",
              "      <td>O</td>\n",
              "      <td>means</td>\n",
              "      <td>NNS</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>space</td>\n",
              "      <td>O</td>\n",
              "      <td>space</td>\n",
              "      <td>NN</td>\n",
              "      <td>space</td>\n",
              "      <td>space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>travel</td>\n",
              "      <td>O</td>\n",
              "      <td>travel</td>\n",
              "      <td>NN</td>\n",
              "      <td>travel</td>\n",
              "      <td>travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>had</td>\n",
              "      <td>O</td>\n",
              "      <td>had</td>\n",
              "      <td>VBD</td>\n",
              "      <td>have</td>\n",
              "      <td>had</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>been</td>\n",
              "      <td>O</td>\n",
              "      <td>been</td>\n",
              "      <td>VBN</td>\n",
              "      <td>be</td>\n",
              "      <td>been</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>devised</td>\n",
              "      <td>O</td>\n",
              "      <td>devised</td>\n",
              "      <td>VBN</td>\n",
              "      <td>devise</td>\n",
              "      <td>devis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              token ner_label spell_corrected  POS           lemma         stem\n",
              "0            French    B-MISC          French   JJ          French       french\n",
              "1            author         O          author   NN          author       author\n",
              "2               who         O             who   WP             who          who\n",
              "3            helped         O          helped  VBD            help         help\n",
              "4            pioner         O         pioneer   NN         pioneer      pioneer\n",
              "5               the         O             the   DT             the          the\n",
              "6   science-fiction         O  sciencefiction   NN  sciencefiction  sciencefict\n",
              "7             genre         O           genre   NN           genre         genr\n",
              "8                 .         O               .    .               .            .\n",
              "9             Verne     B-PER           Verne  NNP           Verne         vern\n",
              "10            wrate         O           wrote  VBD           write        wrote\n",
              "11            about         O           about   IN           about        about\n",
              "12            space         O           space   NN           space        space\n",
              "13                ,         O               ,    ,               ,            ,\n",
              "14              air         O             air   NN             air          air\n",
              "15                ,         O               ,    ,               ,            ,\n",
              "16              and         O             and   CC             and          and\n",
              "17       underwater         O      underwater   JJ      underwater     underwat\n",
              "18           travel         O          travel   NN          travel       travel\n",
              "19           before         O          before   IN          before        befor\n",
              "20        navigable         O       navigable   JJ       navigable        navig\n",
              "21         aircrast         O        aircraft   NN        aircraft     aircraft\n",
              "22              and         O             and   CC             and          and\n",
              "23        practical         O       practical   JJ       practical      practic\n",
              "24       submarines         O      submarines  NNS       submarine     submarin\n",
              "25             were         O            were  VBD              be         were\n",
              "26         invented         O        invented  VBN          invent       invent\n",
              "27                ,         O               ,    ,               ,            ,\n",
              "28              and         O             and   CC             and          and\n",
              "29           before         O          before   IN          before        befor\n",
              "30              any         O             any   DT             any          ani\n",
              "31            means         O           means  NNS            mean         mean\n",
              "32               of         O              of   IN              of           of\n",
              "33            space         O           space   NN           space        space\n",
              "34           travel         O          travel   NN          travel       travel\n",
              "35              had         O             had  VBD            have          had\n",
              "36             been         O            been  VBN              be         been\n",
              "37          devised         O         devised  VBN          devise        devis\n",
              "38                .         O               .    .               .            ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7wmMZPXJhoJ",
        "colab_type": "text"
      },
      "source": [
        "## Spell Checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ69y26MIw09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "39382813-0997-41f3-b9ab-d447a62f79ae"
      },
      "source": [
        "spell_checker = PretrainedPipeline('check_spelling', 'en')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check_spelling download started this may take some time.\n",
            "Approx size to download 892.6 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO9RziOtJzEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = spell_checker.annotate(testDoc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK-ElyC1J72H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca0ddc50-6d3b-40bd-b59c-b5350c88819b"
      },
      "source": [
        "result.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'sentence', 'token', 'checked'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCQwRbO_J-Cx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "0d751ad2-c082-4223-e899-4ef722e45ed7"
      },
      "source": [
        "list(zip(result['token'], result['checked']))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('French', 'French'),\n",
              " ('author', 'author'),\n",
              " ('who', 'who'),\n",
              " ('helped', 'helped'),\n",
              " ('pioner', 'pioneer'),\n",
              " ('the', 'the'),\n",
              " ('science-fiction', 'science-fiction'),\n",
              " ('genre', 'genre'),\n",
              " ('.', '.'),\n",
              " ('Verne', 'Vern'),\n",
              " ('wrate', 'wrote'),\n",
              " ('about', 'about'),\n",
              " ('space', 'space'),\n",
              " (',', ','),\n",
              " ('air', 'air'),\n",
              " (',', ','),\n",
              " ('and', 'and'),\n",
              " ('underwater', 'underwater'),\n",
              " ('travel', 'travel'),\n",
              " ('before', 'before'),\n",
              " ('navigable', 'navigable'),\n",
              " ('aircrast', 'aircraft'),\n",
              " ('and', 'and'),\n",
              " ('practical', 'practical'),\n",
              " ('submarines', 'submarines'),\n",
              " ('were', 'were'),\n",
              " ('invented', 'invented'),\n",
              " (',', ','),\n",
              " ('and', 'and'),\n",
              " ('before', 'before'),\n",
              " ('any', 'any'),\n",
              " ('means', 'means'),\n",
              " ('of', 'of'),\n",
              " ('space', 'space'),\n",
              " ('travel', 'travel'),\n",
              " ('had', 'had'),\n",
              " ('been', 'been'),\n",
              " ('devised', 'devised'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dSzsA1NLxuA",
        "colab_type": "text"
      },
      "source": [
        "## Parsing a list of texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llB04f6sKJgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testDoc_list = [ 'French author who helped pioner the science-fiction genre.',\n",
        "'Verne wrate about space, air, and underwater travel before navigable aircrast',\n",
        "'Practical submarines were invented, and before any means of space travel had been devised.']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_elc3a2IMBUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result_list = pipeline.annotate(testDoc_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOOf0cpCMH2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7862939d-876d-40f2-d80a-e2a89c267bcb"
      },
      "source": [
        "len(result_list)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIzqwkmNMJgY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "61cac004-8dcc-4298-b1ec-f21c24c2f45e"
      },
      "source": [
        "result_list[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': ['French author who helped pioner the science-fiction genre.'],\n",
              " 'lemmas': ['French',\n",
              "  'author',\n",
              "  'who',\n",
              "  'help',\n",
              "  'pioneer',\n",
              "  'the',\n",
              "  'sciencefiction',\n",
              "  'genre',\n",
              "  '.'],\n",
              " 'pos': ['JJ', 'NN', 'WP', 'VBD', 'NN', 'DT', 'NN', 'NN', '.'],\n",
              " 'sentence': ['French author who helped pioner the science-fiction genre.'],\n",
              " 'spell': ['French',\n",
              "  'author',\n",
              "  'who',\n",
              "  'helped',\n",
              "  'pioneer',\n",
              "  'the',\n",
              "  'sciencefiction',\n",
              "  'genre',\n",
              "  '.'],\n",
              " 'stems': ['french',\n",
              "  'author',\n",
              "  'who',\n",
              "  'help',\n",
              "  'pioneer',\n",
              "  'the',\n",
              "  'sciencefict',\n",
              "  'genr',\n",
              "  '.'],\n",
              " 'token': ['French',\n",
              "  'author',\n",
              "  'who',\n",
              "  'helped',\n",
              "  'pioner',\n",
              "  'the',\n",
              "  'science-fiction',\n",
              "  'genre',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebIt_w6FNJ7N",
        "colab_type": "text"
      },
      "source": [
        "## Using fullAnnotate to get more details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhx4qjKxMoH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = 'Peter Parker is a nice guy and lives in New York'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoC3XG-0NX0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detailed_result = pipeline_dl.fullAnnotate(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcYv6-3wNdwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9e03986d-33c2-487f-f95e-0868f642d976"
      },
      "source": [
        "detailed_result"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'checked': [Annotation(token, 0, 4, Peter, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 6, 11, Parker, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 13, 14, is, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 16, 16, a, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 18, 21, nice, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 23, 25, guy, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 27, 29, and, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 31, 35, lives, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 37, 38, in, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 40, 42, New, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 44, 47, York, {'confidence': '1.0', 'sentence': '0'})],\n",
              "  'document': [Annotation(document, 0, 47, Peter Parker is a nice guy and lives in New York, {})],\n",
              "  'embeddings': [Annotation(word_embeddings, 0, 4, Peter, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'Peter', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 6, 11, Parker, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'Parker', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 13, 14, is, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'is', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 16, 16, a, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'a', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 18, 21, nice, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'nice', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 23, 25, guy, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'guy', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 27, 29, and, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'and', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 31, 35, lives, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'lives', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 37, 38, in, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'in', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 40, 42, New, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'New', 'sentence': '0'}),\n",
              "   Annotation(word_embeddings, 44, 47, York, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'York', 'sentence': '0'})],\n",
              "  'entities': [Annotation(chunk, 0, 11, Peter Parker, {'entity': 'PER', 'sentence': '0', 'chunk': '0'}),\n",
              "   Annotation(chunk, 40, 47, New York, {'entity': 'LOC', 'sentence': '0', 'chunk': '1'})],\n",
              "  'lemma': [Annotation(token, 0, 4, Peter, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 6, 11, Parker, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 13, 14, be, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 16, 16, a, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 18, 21, nice, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 23, 25, guy, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 27, 29, and, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 31, 35, life, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 37, 38, in, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 40, 42, New, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 44, 47, York, {'confidence': '1.0', 'sentence': '0'})],\n",
              "  'ner': [Annotation(named_entity, 0, 4, B-PER, {'word': 'Peter'}),\n",
              "   Annotation(named_entity, 6, 11, I-PER, {'word': 'Parker'}),\n",
              "   Annotation(named_entity, 13, 14, O, {'word': 'is'}),\n",
              "   Annotation(named_entity, 16, 16, O, {'word': 'a'}),\n",
              "   Annotation(named_entity, 18, 21, O, {'word': 'nice'}),\n",
              "   Annotation(named_entity, 23, 25, O, {'word': 'guy'}),\n",
              "   Annotation(named_entity, 27, 29, O, {'word': 'and'}),\n",
              "   Annotation(named_entity, 31, 35, O, {'word': 'lives'}),\n",
              "   Annotation(named_entity, 37, 38, O, {'word': 'in'}),\n",
              "   Annotation(named_entity, 40, 42, B-LOC, {'word': 'New'}),\n",
              "   Annotation(named_entity, 44, 47, I-LOC, {'word': 'York'})],\n",
              "  'pos': [Annotation(pos, 0, 4, NNP, {'word': 'Peter'}),\n",
              "   Annotation(pos, 6, 11, NNP, {'word': 'Parker'}),\n",
              "   Annotation(pos, 13, 14, VBZ, {'word': 'is'}),\n",
              "   Annotation(pos, 16, 16, DT, {'word': 'a'}),\n",
              "   Annotation(pos, 18, 21, JJ, {'word': 'nice'}),\n",
              "   Annotation(pos, 23, 25, NN, {'word': 'guy'}),\n",
              "   Annotation(pos, 27, 29, CC, {'word': 'and'}),\n",
              "   Annotation(pos, 31, 35, NNS, {'word': 'lives'}),\n",
              "   Annotation(pos, 37, 38, IN, {'word': 'in'}),\n",
              "   Annotation(pos, 40, 42, NNP, {'word': 'New'}),\n",
              "   Annotation(pos, 44, 47, NNP, {'word': 'York'})],\n",
              "  'sentence': [Annotation(document, 0, 47, Peter Parker is a nice guy and lives in New York, {'sentence': '0'})],\n",
              "  'stem': [Annotation(token, 0, 4, peter, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 6, 11, parker, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 13, 14, i, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 16, 16, a, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 18, 21, nice, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 23, 25, gui, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 27, 29, and, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 31, 35, live, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 37, 38, in, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 40, 42, new, {'confidence': '1.0', 'sentence': '0'}),\n",
              "   Annotation(token, 44, 47, york, {'confidence': '1.0', 'sentence': '0'})],\n",
              "  'token': [Annotation(token, 0, 4, Peter, {'sentence': '0'}),\n",
              "   Annotation(token, 6, 11, Parker, {'sentence': '0'}),\n",
              "   Annotation(token, 13, 14, is, {'sentence': '0'}),\n",
              "   Annotation(token, 16, 16, a, {'sentence': '0'}),\n",
              "   Annotation(token, 18, 21, nice, {'sentence': '0'}),\n",
              "   Annotation(token, 23, 25, guy, {'sentence': '0'}),\n",
              "   Annotation(token, 27, 29, and, {'sentence': '0'}),\n",
              "   Annotation(token, 31, 35, lives, {'sentence': '0'}),\n",
              "   Annotation(token, 37, 38, in, {'sentence': '0'}),\n",
              "   Annotation(token, 40, 42, New, {'sentence': '0'}),\n",
              "   Annotation(token, 44, 47, York, {'sentence': '0'})]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMFP_3y4NfJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d544b1d4-0677-4da3-a65d-4b6c414c3528"
      },
      "source": [
        "detailed_result[0]['entities']"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Annotation(chunk, 0, 11, Peter Parker, {'entity': 'PER', 'sentence': '0', 'chunk': '0'}),\n",
              " Annotation(chunk, 40, 47, New York, {'entity': 'LOC', 'sentence': '0', 'chunk': '1'})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQZu_E43VRPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40b5b843-651e-48f9-d5ed-5e6e7b949e60"
      },
      "source": [
        "detailed_result[0]['entities'][0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Annotation(chunk, 0, 11, Peter Parker, {'entity': 'PER', 'sentence': '0', 'chunk': '0'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvtsAdOdVS-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d073426-0078-4120-e362-6e5029d8a2cd"
      },
      "source": [
        "# To reach the value we use .result method\n",
        "detailed_result[0]['entities'][0].result"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Peter Parker'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4K2R0WHVVOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6720dbdb-30cb-42f0-828a-8312c8e04e8e"
      },
      "source": [
        "detailed_result[0]['entities'][0].metadata['entity']"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PER'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx5X3YybN9UW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chunks = []\n",
        "entities = []\n",
        "\n",
        "for n in detailed_result[0]['entities']:\n",
        "    chunks.append(n.result)\n",
        "    entities.append(n.metadata['entity'])\n",
        "\n",
        "df = pd.DataFrame({'chunks':chunks, 'entities':entities})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jPvNZkpRnph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "ecf06e49-9239-4da4-a02b-01b4b05f001f"
      },
      "source": [
        "df"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_id</th>\n",
              "      <th>token</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>pos</th>\n",
              "      <th>ner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Peter</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Parker</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>is</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nice</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>JJ</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>guy</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>and</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>lives</td>\n",
              "      <td>31</td>\n",
              "      <td>35</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>in</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>New</td>\n",
              "      <td>40</td>\n",
              "      <td>42</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>York</td>\n",
              "      <td>44</td>\n",
              "      <td>47</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sent_id   token  start  end  pos    ner\n",
              "0         0   Peter      0    4  NNP  B-PER\n",
              "1         0  Parker      6   11  NNP  I-PER\n",
              "2         0      is     13   14  VBZ      O\n",
              "3         0       a     16   16   DT      O\n",
              "4         0    nice     18   21   JJ      O\n",
              "5         0     guy     23   25   NN      O\n",
              "6         0     and     27   29   CC      O\n",
              "7         0   lives     31   35  NNS      O\n",
              "8         0      in     37   38   IN      O\n",
              "9         0     New     40   42  NNP  B-LOC\n",
              "10        0    York     44   47  NNP  I-LOC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG6IEJr6Ulno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "05b43dcc-5246-43b5-896c-1e3cdb4aeb8a"
      },
      "source": [
        "tuples = []\n",
        "\n",
        "for x, y, z in zip(detailed_result[0][\"token\"], detailed_result[0]['pos'], detailed_result[0]['ner']):\n",
        "    tuples.append((int(x.metadata['sentence']), x.result, x.begin, x.end, y.result, z.result))\n",
        "\n",
        "df = pd.DataFrame(tuples, columns=['sent_id', 'token', 'start', 'end', 'pos', 'ner'])\n",
        "df"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent_id</th>\n",
              "      <th>token</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>pos</th>\n",
              "      <th>ner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Peter</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Parker</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>is</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>a</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nice</td>\n",
              "      <td>18</td>\n",
              "      <td>21</td>\n",
              "      <td>JJ</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>guy</td>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>and</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>CC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>lives</td>\n",
              "      <td>31</td>\n",
              "      <td>35</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>in</td>\n",
              "      <td>37</td>\n",
              "      <td>38</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>New</td>\n",
              "      <td>40</td>\n",
              "      <td>42</td>\n",
              "      <td>NNP</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>York</td>\n",
              "      <td>44</td>\n",
              "      <td>47</td>\n",
              "      <td>NNP</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sent_id   token  start  end  pos    ner\n",
              "0         0   Peter      0    4  NNP  B-PER\n",
              "1         0  Parker      6   11  NNP  I-PER\n",
              "2         0      is     13   14  VBZ      O\n",
              "3         0       a     16   16   DT      O\n",
              "4         0    nice     18   21   JJ      O\n",
              "5         0     guy     23   25   NN      O\n",
              "6         0     and     27   29   CC      O\n",
              "7         0   lives     31   35  NNS      O\n",
              "8         0      in     37   38   IN      O\n",
              "9         0     New     40   42  NNP  B-LOC\n",
              "10        0    York     44   47  NNP  I-LOC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc-Bo9r5XGLt",
        "colab_type": "text"
      },
      "source": [
        "## Use Pretrained **match_chunk** Pipeline for individual Noun Phrase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Szw_bvlX-5-",
        "colab_type": "text"
      },
      "source": [
        "pipeline uses the regex pattern of `<DT>?<JJ>*<NN>+` (yani determinat (DT) etiher the or a might occur, one or more adjective (JJ) and noun (NN) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGlYgC-cV0jq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "03677f0b-c744-4c99-bb54-7dd1ec29661f"
      },
      "source": [
        "pipeline = PretrainedPipeline('match_chunks', 'en')\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "match_chunks download started this may take some time.\n",
            "Approx size to download 4.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppFrKptDYder",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pipeline.annotate('The book has many chapters. The red car seems awesome')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0JhdIe4Ypy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "61e1b374-2fa9-4258-c78c-9f4ba920759c"
      },
      "source": [
        "result"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chunk': ['The book', 'The red car'],\n",
              " 'document': ['The book has many chapters. The red car seems awesome'],\n",
              " 'pos': ['DT', 'NN', 'VBZ', 'JJ', 'NNS', '.', 'DT', 'JJ', 'NN', 'VBZ', 'JJ'],\n",
              " 'sentence': ['The book has many chapters.', 'The red car seems awesome'],\n",
              " 'token': ['The',\n",
              "  'book',\n",
              "  'has',\n",
              "  'many',\n",
              "  'chapters',\n",
              "  '.',\n",
              "  'The',\n",
              "  'red',\n",
              "  'car',\n",
              "  'seems',\n",
              "  'awesome']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh2dsVQCYrLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pipeline.annotate('the little brown pitty bird was trying to fly and the green dog was barking at it')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4DtJiEkZHI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "b216a7cb-2e53-481a-dc51-d2df86d3ad3a"
      },
      "source": [
        "result"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chunk': ['the little brown pitty bird', 'the green dog'],\n",
              " 'document': ['the little brown pitty bird was trying to fly and the green dog was barking at it'],\n",
              " 'pos': ['DT',\n",
              "  'JJ',\n",
              "  'JJ',\n",
              "  'NN',\n",
              "  'NN',\n",
              "  'VBD',\n",
              "  'VBG',\n",
              "  'TO',\n",
              "  'VB',\n",
              "  'CC',\n",
              "  'DT',\n",
              "  'JJ',\n",
              "  'NN',\n",
              "  'VBD',\n",
              "  'VBG',\n",
              "  'IN',\n",
              "  'PRP'],\n",
              " 'sentence': ['the little brown pitty bird was trying to fly and the green dog was barking at it'],\n",
              " 'token': ['the',\n",
              "  'little',\n",
              "  'brown',\n",
              "  'pitty',\n",
              "  'bird',\n",
              "  'was',\n",
              "  'trying',\n",
              "  'to',\n",
              "  'fly',\n",
              "  'and',\n",
              "  'the',\n",
              "  'green',\n",
              "  'dog',\n",
              "  'was',\n",
              "  'barking',\n",
              "  'at',\n",
              "  'it']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fig-Ge0IZIC0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3e0c31d-02f0-4b7d-da2c-45dcd1a4e672"
      },
      "source": [
        "result['chunk']"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the little brown pitty bird']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR7t6vtxllzV",
        "colab_type": "text"
      },
      "source": [
        "## Extract Exact Dates afrom Referential Date Phrahes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiYerG35ZPkk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "614b28e2-61c2-4b8b-a077-9c1ef0a23278"
      },
      "source": [
        "pipeline = PretrainedPipeline('match_datetime', 'en')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "match_datetime download started this may take some time.\n",
            "Approx size to download 12.9 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjxHYCjAmBID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pipeline.annotate('I saw him yesterday and he told me that he would visit us next week.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oToHwIikmNeX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "f7f587c3-3f7d-4f23-81fe-6071be479679"
      },
      "source": [
        "result"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': ['2020/04/27', '2020/04/19'],\n",
              " 'document': ['I saw him yesterday and he told me that he would visit us next week.'],\n",
              " 'sentence': ['I saw him yesterday and he told me that he would visit us next week.'],\n",
              " 'token': ['I',\n",
              "  'saw',\n",
              "  'him',\n",
              "  'yesterday',\n",
              "  'and',\n",
              "  'he',\n",
              "  'told',\n",
              "  'me',\n",
              "  'that',\n",
              "  'he',\n",
              "  'would',\n",
              "  'visit',\n",
              "  'us',\n",
              "  'next',\n",
              "  'week',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A89g6O8imRiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pipeline.fullAnnotate('I saw him yesterday and he told me that he would visit us next week.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv5Tqx-SnyLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "5a446a3e-d50d-420d-dbcb-50e1f286c80d"
      },
      "source": [
        "result"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'date': [Annotation(date, 58, 66, 2020/04/27, {'sentence': '0'}),\n",
              "   Annotation(date, 10, 18, 2020/04/19, {'sentence': '0'})],\n",
              "  'document': [Annotation(document, 0, 67, I saw him yesterday and he told me that he would visit us next week., {})],\n",
              "  'sentence': [Annotation(document, 0, 67, I saw him yesterday and he told me that he would visit us next week., {'sentence': '0'})],\n",
              "  'token': [Annotation(token, 0, 0, I, {'sentence': '0'}),\n",
              "   Annotation(token, 2, 4, saw, {'sentence': '0'}),\n",
              "   Annotation(token, 6, 8, him, {'sentence': '0'}),\n",
              "   Annotation(token, 10, 18, yesterday, {'sentence': '0'}),\n",
              "   Annotation(token, 20, 22, and, {'sentence': '0'}),\n",
              "   Annotation(token, 24, 25, he, {'sentence': '0'}),\n",
              "   Annotation(token, 27, 30, told, {'sentence': '0'}),\n",
              "   Annotation(token, 32, 33, me, {'sentence': '0'}),\n",
              "   Annotation(token, 35, 38, that, {'sentence': '0'}),\n",
              "   Annotation(token, 40, 41, he, {'sentence': '0'}),\n",
              "   Annotation(token, 43, 47, would, {'sentence': '0'}),\n",
              "   Annotation(token, 49, 53, visit, {'sentence': '0'}),\n",
              "   Annotation(token, 55, 56, us, {'sentence': '0'}),\n",
              "   Annotation(token, 58, 61, next, {'sentence': '0'}),\n",
              "   Annotation(token, 63, 66, week, {'sentence': '0'}),\n",
              "   Annotation(token, 67, 67, ., {'sentence': '0'})]}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vymPiVyoFG2",
        "colab_type": "text"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mqnp33bnzFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8a3bed44-22a6-4050-94b4-38a7fe7f9eec"
      },
      "source": [
        "pipeline =PretrainedPipeline('analyze_sentiment', 'en')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2Vqv7v2ofjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = pipeline.annotate('The movie I watched was not a good one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMSOT4jXpeKC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "81702475-95bd-401d-c438-b116405d9cf4"
      },
      "source": [
        "result"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'checked': ['The', 'movie', 'I', 'watched', 'was', 'not', 'a', 'good', 'one'],\n",
              " 'document': ['The movie I watched was not a good one'],\n",
              " 'sentence': ['The movie I watched was not a good one'],\n",
              " 'sentiment': ['negative'],\n",
              " 'token': ['The', 'movie', 'I', 'watched', 'was', 'not', 'a', 'good', 'one']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uV-mK5zpe8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d5e2d93f-7e6f-4f98-cf24-70a6068c22bf"
      },
      "source": [
        "result['sentiment']"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nb7cDSGprhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}